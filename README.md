# Project 1 - Water小组
# 11/26 update
已经实现了PDF下载的框架(PDFItem)，不必重新造轮子

使用时实例化该类，指定`'file_names'` 和 `'file_urls'`两个字段后yield该对象即可



本项目实现了一个xxx

## 任务要求

+ 至少爬取以下三个数据库中的资源，图书馆数据源为**可选加分项**
    + **ACM必选**，要保证爬到的论文中有一定比例的**视频**，可以是在线观看视频的url地址，也可以是下载视频到本地后的文件路径
    + **Springer必选**
    + **ScienceDirect必选**，要求包含**多领域**的数据
+ 爬到的数据必须存储到[MongoDB](https://www.mongodb.com)中。
+ 数据源越丰富越好，当从不同数据源爬取到相同论文时，需要**去除重复数据**
+ 从每个数据源获取的数据需要具有**完备性**，即爬取数据量占全站数据量的比例越高越好
+ 要求搭建一个完整的**爬虫框架**，在爬取不同的数据源时，只需要根据实际情况，手写少量解析网页的部分，即数据源是可插拔的
+ 要求实现**增量式**爬取，定时更新
+ 要求爬虫至少采用如下技术手段：
    + 当爬取一个规模较大的网站时，采用某种策略/顺序，保证爬取结果不重不漏
    + 使用多线程/多进程等技术提升爬虫效率
    + 使用ip池、调整等待时间等技术抵御网站反爬
    + 如果网络崩溃，能够从断点续爬
    + 使用日志技术实时展示爬取进度
+ 搭建一个基本的[Elasticsearch](https://www.elastic.co/) + [Kibana](https://www.elastic.co/cn/kibana/) 检索系统，对爬取的数据建立索引，方便展示

## 小组成员及分工

## 下载使用

### 依赖项安装

- Scrapy框架：`pip install scrapy`
- PyMongo：`pip install pymongo`

### 数据库安装部署

### 项目运行

## 爬虫内容及统计信息

